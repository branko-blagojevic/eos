#!/usr/bin/env python

#    Copyright (C) 2001  Jeff Epler  <jepler@unpythonic.dhs.org>
#    Copyright (C) 2006  Csaba Henk  <csaba.henk@creo.hu>
#
#    This program can be distributed under the terms of the GNU LGPL.
#    See the file COPYING.
#

from __future__ import print_function

import os, posix, re, stat, sys
import pdb
from errno import *
from stat import *
import fcntl, json

# pull in some spaghetti to make this stuff work without fuse-py being installed
try:
    import _find_fuse_parts
except ImportError:
    pass
import fuse
from fuse import Fuse

ctlg={}

if not hasattr(fuse, '__version__'):
    raise RuntimeError( "your fuse-py doesn't know of fuse.__version__, probably it's too old." )

fuse.fuse_python_api = (0, 2)

fuse.feature_assert('stateful_files', 'has_init')


def flag2mode(flags):
    md = {os.O_RDONLY: 'r', os.O_WRONLY: 'w', os.O_RDWR: 'w+'}
    m = md[flags & (os.O_RDONLY | os.O_WRONLY | os.O_RDWR)]

    if flags | os.O_APPEND:
        m = m.replace('w', 'a', 1)

    return m


class Bck(Fuse):

    def __init__(self, *args, **kw):

        Fuse.__init__(self, *args, **kw)

        # do stuff to set up your filesystem here, if you want
        #import thread
        #thread.start_new_thread(self.mythread, ())
        self.root = '/'


#    def mythread(self):
#
#        """
#        The beauty of the FUSE python implementation is that with the python interp
#        running in foreground, you can have threads
#        """
#        print "mythread: started"
#        while 1:
#            time.sleep(120)
#            print "mythread: ticking"

    def getattr(self, path):
        if path not in ctlg: path += "/"
        print("path=%r" % path)
        try:
            print(ctlg[path]['s'])
            return ctlg[path]['s']
        except Exception as e:
            print("Exception %r" % e)

    def readlink(self, path):
        pdb.set_trace()
        return os.readlink("." + path)

    def readdir(self, path, offset):
        if path != "/": path += "/"         # this is a dir
        print("path=%r" % path)
        for e in filter(lambda a: type(a) is str and a.startswith(path), ctlg.keys()):
            print("e1='%s'" % e)
            if len(e) > 0 and e[:len(path)] == path:
                suffix = str(e[len(path):])
                print("suffix='%s'" % suffix)
                if len(suffix) == 0: continue
                #if '/' not in suffix or suffix.find("/") == len(suffix)-1:
                if '/' not in suffix:
                    print("yield %r" % suffix)
                    yield fuse.Direntry(suffix)
                elif len(suffix) > 1 and suffix.find("/") == len(suffix)-1:
                    print("yield %r" % suffix[:-1])
                    yield fuse.Direntry(suffix[:-1])

    def unlink(self, path):
        pdb.set_trace()
        os.unlink("." + path)

    def rmdir(self, path):
        pdb.set_trace()
        os.rmdir("." + path)

    def symlink(self, path, path1):
        pdb.set_trace()
        os.symlink(path, "." + path1)

    def rename(self, path, path1):
        pdb.set_trace()
        os.rename("." + path, "." + path1)

    def link(self, path, path1):
        pdb.set_trace()
        os.link("." + path, "." + path1)

    def chmod(self, path, mode):
        pdb.set_trace()
        os.chmod("." + path, mode)

    def chown(self, path, user, group):
        pdb.set_trace()
        os.chown("." + path, user, group)

    def truncate(self, path, len):
        pdb.set_trace()
        f = open("." + path, "a")
        f.truncate(len)
        f.close()

    def mknod(self, path, mode, dev):
        pdb.set_trace()
        os.mknod("." + path, mode, dev)

    def mkdir(self, path, mode):
        pdb.set_trace()
        os.mkdir("." + path, mode)

    def utime(self, path, times):
        pdb.set_trace()
        os.utime("." + path, times)

#    The following utimens method would do the same as the above utime method.
#    We can't make it better though as the Python stdlib doesn't know of
#    subsecond preciseness in acces/modify times.
#  
#    def utimens(self, path, ts_acc, ts_mod):
#      os.utime("." + path, (ts_acc.tv_sec, ts_mod.tv_sec))

    def access(self, path, mode):
        return
        pdb.set_trace()
        if not os.access("." + path, mode):
            return -EACCES

#    This is how we could add stub extended attribute handlers...
#    (We can't have ones which aptly delegate requests to the underlying fs
#    because Python lacks a standard xattr interface.)
#
#    def getxattr(self, path, name, size):
#        val = name.swapcase() + '@' + path
#        if size == 0:
#            # We are asked for size of the value.
#            return len(val)
#        return val
#
#    def listxattr(self, path, size):
#        # We use the "user" namespace to please XFS utils
#        aa = ["user." + a for a in ("foo", "bar")]
#        if size == 0:
#            # We are asked for size of the attr list, ie. joint size of attrs
#            # plus null separators.
#            return len("".join(aa)) + len(aa)
#        return aa

    def statfs(self):
        """
        Should return an object with statvfs attributes (f_bsize, f_frsize...).
        Eg., the return value of os.statvfs() is such a thing (since py 2.2).
        If you are not reusing an existing statvfs object, start with
        fuse.StatVFS(), and define the attributes.

        To provide usable information (ie., you want sensible df(1)
        output, you are suggested to specify the following attributes:

            - f_bsize - preferred size of file blocks, in bytes
            - f_frsize - fundamental size of file blcoks, in bytes
                [if you have no idea, use the same as blocksize]
            - f_blocks - total number of blocks in the filesystem
            - f_bfree - number of free blocks
            - f_files - total number of file inodes
            - f_ffree - nunber of free file inodes
        """

        pdb.set_trace()
        return os.statvfs(".")

    def fsinit(self):
        os.chdir(self.root)

    class BckFile(object):

        def __init__(self, path, flags, *mode):
            #pdb.set_trace()
            self.entry = ctlg[path]
            bIndex, self.bOffset, self.bLen = map(int, self.entry['b'].split(":"))
            cloneId = self.entry['c']
            blobFn = "%s/b.%d" % (ctlg[cloneId]['path'], bIndex)
            self.blobFile = open(blobFn, "r")
            #self.file = os.fdopen(os.open("." + path, flags, *mode), flag2mode(flags))
            #self.fd = self.file.fileno()

        def read(self, length, offset):
            #clonePath = self.entry['cp']
            #rlen = len(clonePath) - offset         # remaining length
            #if rlen > 0: return(clonePath[offset:rlen])
            #return ''
            #self.file.seek(offset)
            #return self.file.read(length)
            #pdb.set_trace()
            self.blobFile.seek(self.bOffset+offset)
            maxLen = self.bLen - offset
            if maxLen > length: maxLen = length
            return self.blobFile.read(maxLen)


        def write(self, buf, offset):
            pdb.set_trace()
            self.file.seek(offset)
            self.file.write(buf)
            return len(buf)

        def release(self, flags):
            #pdb.set_trace()
            self.blobFile.close()
            return

        def _fflush(self):
            pdb.set_trace()
            if 'w' in self.file.mode or 'a' in self.file.mode:
                self.file.flush()

        def fsync(self, isfsyncfile):
            pdb.set_trace()
            self._fflush()
            if isfsyncfile and hasattr(os, 'fdatasync'):
                os.fdatasync(self.fd)
            else:
                os.fsync(self.fd)

        def flush(self):
            #pdb.set_trace()
            #self._fflush()
            # cf. xmp_flush() in fusexmp_fh.c
            #os.close(os.dup(self.fd))
            return

        def fgetattr(self):
            return self.entry['s']

        def ftruncate(self, len):
            pdb.set_trace()
            self.file.truncate(len)

        def lock(self, cmd, owner, **kw):
            return
            pdb.set_trace()
            # The code here is much rather just a demonstration of the locking
            # API than something which actually was seen to be useful.

            # Advisory file locking is pretty messy in Unix, and the Python
            # interface to this doesn't make it better.
            # We can't do fcntl(2)/F_GETLK from Python in a platfrom independent
            # way. The following implementation *might* work under Linux. 
            #
            # if cmd == fcntl.F_GETLK:
            #     import struct
            # 
            #     lockdata = struct.pack('hhQQi', kw['l_type'], os.SEEK_SET,
            #                            kw['l_start'], kw['l_len'], kw['l_pid'])
            #     ld2 = fcntl.fcntl(self.fd, fcntl.F_GETLK, lockdata)
            #     flockfields = ('l_type', 'l_whence', 'l_start', 'l_len', 'l_pid')
            #     uld2 = struct.unpack('hhQQi', ld2)
            #     res = {}
            #     for i in xrange(len(uld2)):
            #          res[flockfields[i]] = uld2[i]
            #  
            #     return fuse.Flock(**res)

            # Convert fcntl-ish lock parameters to Python's weird
            # lockf(3)/flock(2) medley locking API...
            op = { fcntl.F_UNLCK : fcntl.LOCK_UN,
                   fcntl.F_RDLCK : fcntl.LOCK_SH,
                   fcntl.F_WRLCK : fcntl.LOCK_EX }[kw['l_type']]
            if cmd == fcntl.F_GETLK:
                return -EOPNOTSUPP
            elif cmd == fcntl.F_SETLK:
                if op != fcntl.LOCK_UN:
                    op |= fcntl.LOCK_NB
            elif cmd == fcntl.F_SETLKW:
                pass
            else:
                return -EINVAL

            fcntl.lockf(self.fd, op, kw['l_start'], kw['l_len'])


    def main(self, *a, **kw):

        self.file_class = self.BckFile

        return Fuse.main(self, *a, **kw)


def find_blobs(regs):
    blobs = {}
    
    res = []
    for regexp in regs:
        print("check for '%s'" % regexp)
        res.append(re.compile(regexp))

    for k in ctlg.keys():
        if type(k) is str and 'b' in ctlg[k]:
            for rx in res:
                if rx.search(k):
                    bIndex, bOffset, bLen = map(int, ctlg[k]['b'].split(":"))
                    cloneId = ctlg[k]['c']
                    blobFn = "%s/b.%d" % (ctlg[cloneId]['path'], bIndex)
                    try:
                        blobs[blobFn] += 1
                    except KeyError:
                        blobs[blobFn] = 1

    for k in blobs:
        print(k, blobs[k])


def parse_cat_files(s):
    try:
        catFiles = s.files.split(',')
    except Exception as e:
        pdb.set_trace()

    # build a dictionary of files in the backup, implementing incremental logic
    for fn in catFiles:
        lastCatFile = fn == catFiles[-1]

        ff = open(fn, "r")
        line1 = ff.readline()
        xx = json.loads(line1)
        cloneId = int(xx['c'])                       # top dir has this dump's cloneId
        rootPath = str(xx['n'])[:-1]                 # excluding final "/"
        ctlg[cloneId] = dict(path=os.path.dirname(fn))

        ff.seek(0,0)                            # rewind

        while True:
            l = ff.readline()
            if l == '': break

            try:
                xx = json.loads(l)
            #except json.decoder.JSONDecodeError as e:          # python 3
            except Exception as e:
                pdb.set_trace()
                print("json error %r l='%s'" % (e, l), file=sys.stderr)
                sys.exit(1)

            path = str(xx['n'])                      # bloody unicode
            #if not path.endswith('/'): clonePath = "%s/%s" % (xx['c'], xx['p'])

            rpath = path[len(rootPath):]	# skip the "root" part
            if rpath in ctlg and not path.endswith('/'):        # this is a file which we've got already
              try:
                if cloneId != xx['c']:                          # file not part of this backup
                    if lastCatFile: ctlg[rpath]['keep'] = True  # but it must survive
                    continue                                 
                if xx['t'] < ctlg[rpath]['t'] or xx['c'] == 0:    # ??? file exists but not part of this backup ?????
                    if lastCatFile: ctlg[rpath]['keep'] = True
                    continue		# restore latest version
              except Exception as e:
                  pdb.set_trace()
                  print(e)
            else: ctlg[rpath] = dict()

            mode = 0o777
            if len(rpath) == 0 or rpath.endswith("/"): mode |= stat.S_IFDIR
            ctlg[rpath]['s'] = posix.stat_result(eval(xx['st']))
            ctlg[rpath]['t'] = xx['t']                              # server sync time
            if 'p' in xx:                                           # this is a file
              ctlg[rpath]['cp'] = "%d/%s" % (xx['c'], str(xx['p'])) # clone path
              ctlg[rpath]['b'] = xx['b']
              ctlg[rpath]['c'] = xx['c']                            # cloneId needed for blob file path
            if lastCatFile: ctlg[rpath]['keep'] = True


    #pdb.set_trace()
    # remove deleted files
    for p in sorted(ctlg.keys()):	# sorted so that dirs come before their files
        if type(p) is str and not 'keep' in ctlg[p]: del ctlg[p]

def main():

    usage = """
Mount a R/O file system based on a series of eos-backup catalogs

""" + Fuse.fusage

    server = Bck(version="%prog " + fuse.__version__,
                 usage=usage,
                 dash_s_do='setsingle')

    server.parser.add_option(mountopt="root", metavar="PATH", default='/',
                             help="mirror filesystem from under PATH [default: %default]")
    server.parser.add_option("-F", "--files")
    server.parser.add_option("-L", "--locate")
    server.parse(values=server, errex=1)

# parse catalog Files
    parse_cat_files(server)

    try:
        regs = server.locate.split(',')
        find_blobs(regs)
        sys.exit(0)
    except AttributeError: pass

    try:
        if server.fuse_args.mount_expected():
            os.chdir(server.root)
    except OSError:
        print >> sys.stderr, "can't enter root of underlying filesystem"
        sys.exit(1)

    server.main()


if __name__ == '__main__':
    main()
